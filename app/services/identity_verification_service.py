# identity_verification_service.py
import uuid
import os
import json
from datetime import datetime
import tensorflow as tf
import numpy as np
import cv2
import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
from PIL import Image

from app.core.model_loader import model_loader
from app.core.config import settings
from app.core.database import get_db
from app.repositories.training_repository import TrainingRepository
from app.model.training_result import TrainingResult
from app.model.training_sample import TrainingSample
from app.model.identity import Identity
from app.utils.grad_cam_utils import make_gradcam_heatmap, save_heatmap_image
import logging

logger = logging.getLogger(__name__)

class IdentityVerificationService:
    def __init__(self):
        self.identity_model = None  # Model 1: Nh·∫≠n di·ªán danh t√≠nh (so s√°nh embedding)
        self.image_fake_detection_model = None  # Model 2a: Ph√°t hi·ªán real/fake ·∫£nh
        self.video_fake_detection_model = None  # Model 2b: Ph√°t hi·ªán real/fake video
        self.embedding_model = None  # FaceNet ƒë·ªÉ extract embedding
        self.embedding_db = None
        self.person_db = None
        self.threshold = 0.6  # Threshold cho face recognition
        self.db_session = None
        self.training_repo = None
        logger.info("üîÑ IdentityVerificationService initialized")
    
    async def initialize(self):
        """Kh·ªüi t·∫°o service m·ªôt c√°ch r√µ r√†ng"""
        try:
            logger.info("üîÑ Starting IdentityVerificationService initialization...")
            self.db_session = next(get_db())
            self.training_repo = TrainingRepository(self.db_session)
            
            await self.load_identity_system()
            logger.info("‚úÖ IdentityVerificationService fully initialized")
        except Exception as e:
            logger.error(f"‚ùå Failed to initialize IdentityVerificationService: {e}")
            raise
    
    async def load_identity_system(self):
        """Load c·∫£ 3 model theo config"""
        try:
            logger.info("üîÑ Loading identity system with 3 models...")
            
            # MODEL 1: Load identity recognition model (n·∫øu c√≥)
            identity_model_path = settings.IDENTITY_MODEL_PATH
            logger.info(f"üîç Looking for Identity model at: {identity_model_path}")
            logger.info(f"üîç Path exists: {identity_model_path.exists()}")
            
            if identity_model_path.exists():
                self.identity_model = tf.keras.models.load_model(identity_model_path)
                logger.info("‚úÖ Model 1 - Identity recognition loaded")
                logger.info(f"üìÅ Model path: {identity_model_path}")
            else:
                logger.warning("‚ö†Ô∏è Model 1 - Identity model not found, using FaceNet only")
            
            # MODEL 2a: Load fake detection model cho ·∫£nh
            image_model_path = settings.IMAGE_MODEL_PATH
            logger.info(f"üîç Looking for Image Fake Detection model at: {image_model_path}")
            logger.info(f"üîç Path exists: {image_model_path.exists()}")
            
            if image_model_path.exists():
                self.image_fake_detection_model = tf.keras.models.load_model(image_model_path)
                logger.info("‚úÖ Model 2a - Image Fake Detection loaded")
                logger.info(f"üìÅ Model path: {image_model_path}")
            else:
                logger.error("‚ùå Model 2a - Image Fake Detection model not found")
                return False
            
            # MODEL 2b: Load fake detection model cho video
            video_model_path = settings.VIDEO_MODEL_PATH
            logger.info(f"üîç Looking for Video Fake Detection model at: {video_model_path}")
            logger.info(f"üîç Path exists: {video_model_path.exists()}")
            
            if video_model_path.exists():
                self.video_fake_detection_model = tf.keras.models.load_model(video_model_path)
                logger.info("‚úÖ Model 2b - Video Fake Detection loaded")
                logger.info(f"üìÅ Model path: {video_model_path}")
            else:
                logger.error("‚ùå Model 2b - Video Fake Detection model not found")
                return False
            
            # FaceNet for embedding extraction
            self.embedding_model = self._load_embedding_model()
            
            # Load embedding database
            await self._load_identity_database()
            
            logger.info("‚úÖ All 3 models loaded successfully")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error loading identity system: {e}")
            return False
    
    async def _load_identity_database(self):
        """Load database v·ªõi query t·ªëi ∆∞u"""
        try:
            from sqlalchemy.orm import joinedload
            
            logger.info("üîÑ Loading identity database...")
            
            # Ch·ªâ load c√°c field th·ª±c s·ª± c·∫ßn thi·∫øt
            results = self.db_session.query(
                TrainingResult.id,
                TrainingResult.embedding,
                TrainingResult.training_sample_id,
                TrainingResult.file_path,
                TrainingResult.created_at,
                TrainingSample.id.label('sample_id'),
                TrainingSample.type,
                TrainingSample.label,
                TrainingSample.file_path.label('sample_file_path'),
                Identity.id.label('identity_id'),
                Identity.name
            )\
            .join(TrainingResult.sample)\
            .outerjoin(TrainingSample.identity)\
            .filter(TrainingResult.embedding.isnot(None))\
            .all()
            
            logger.info(f"üîç SQL query returned {len(results)} records with embeddings")
            
            self.embedding_db = []
            self.person_db = []
            
            valid_count = 0
            invalid_count = 0
            
            for i, result in enumerate(results):
                try:
                    if result.embedding is None:
                        invalid_count += 1
                        continue
                        
                    # Parse embedding
                    if isinstance(result.embedding, str):
                        embedding_str = result.embedding.strip('[]')
                        numbers = [float(x.strip()) for x in embedding_str.split(',')]
                        embedding = np.array(numbers)
                    elif isinstance(result.embedding, (list, np.ndarray)):
                        embedding = np.array(result.embedding)
                    else:
                        logger.warning(f"‚ö†Ô∏è Unknown embedding type: {type(result.embedding)}")
                        invalid_count += 1
                        continue
                    
                    # Validate embedding
                    if len(embedding) == 512:
                        person_info = {
                            'identity_id': result.identity_id,
                            'name': result.name or f"Unknown_{result.sample_id}",
                            'training_sample_id': result.sample_id,
                            'training_result_id': result.id,
                            'file_path': result.sample_file_path or result.file_path,
                            'sample_type': result.type,
                            'label': result.label,
                            'embedding': embedding,
                            'created_at': result.created_at
                        }
                        
                        self.embedding_db.append(embedding)
                        self.person_db.append(person_info)
                        valid_count += 1
                        
                    else:
                        invalid_count += 1
                        logger.warning(f"‚ö†Ô∏è Invalid embedding dimension: {len(embedding)} (expected 512)")
                            
                except Exception as e:
                    invalid_count += 1
                    logger.warning(f"‚ö†Ô∏è Error parsing embedding record {i+1}: {e}")
                    continue
            
            logger.info(f"‚úÖ FINISHED: Loaded {valid_count} valid embeddings, {invalid_count} invalid")
            logger.info(f"üìä Embedding DB size: {len(self.embedding_db)}, Person DB size: {len(self.person_db)}")
            
            if self.embedding_db:
                logger.info(f"üîç First person sample: {self.person_db[0]['name']}")
            else:
                logger.warning("‚ö†Ô∏è No embeddings loaded from database!")
            
        except Exception as e:
            logger.error(f"‚ùå Error loading identity database: {e}")
            raise

    def _load_embedding_model(self):
        """Load model ƒë·ªÉ extract embedding"""
        try:
            from keras_facenet import FaceNet
            embedder = FaceNet()
            logger.info("‚úÖ FaceNet embedding model loaded")
            return embedder
        except Exception as e:
            logger.error(f"‚ùå Error loading FaceNet: {e}")
            return None
    
    async def _extract_embedding(self, file, file_type):
        """Extract embedding t·ª´ file input"""
        try:
            if self.embedding_model is None:
                return None
            
            # L∆∞u file t·∫°m
            file_extension = file.filename.split('.')[-1]
            filename = f"temp_{uuid.uuid4()}.{file_extension}"
            
            if file_type == "image":
                file_path = settings.IMAGE_UPLOAD_DIR / filename
            else:
                file_path = settings.VIDEO_UPLOAD_DIR / filename
            
            # Save file
            with open(file_path, "wb") as buffer:
                content = await file.read()
                buffer.write(content)
            
            # Extract embedding
            if file_type == "image":
                embedding = self._extract_image_embedding(file_path)
            else:
                embedding = self._extract_video_embedding(file_path)
            
            # X√≥a file t·∫°m
            try:
                os.remove(file_path)
            except:
                pass
            
            return embedding
            
        except Exception as e:
            logger.error(f"‚ùå Embedding extraction error: {e}")
            return None
    
    def _extract_image_embedding(self, image_path):
        """Extract embedding t·ª´ image"""
        try:
            image = cv2.imread(str(image_path))
            if image is None:
                return None
                
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            image_resized = cv2.resize(image_rgb, (160, 160))
            
            embeddings = self.embedding_model.embeddings([image_resized])
            return embeddings[0]
            
        except Exception as e:
            logger.error(f"‚ùå Image embedding extraction error: {e}")
            return None
    
    def _extract_video_embedding(self, video_path):
        """Extract embedding t·ª´ video"""
        try:
            cap = cv2.VideoCapture(str(video_path))
            frame_embeddings = []
            frame_count = 0
            
            while cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    break
                    
                if frame_count % settings.IDENTITY_CONFIG["frame_interval"] == 0:
                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    frame_embedding = self._extract_single_frame_embedding(frame_rgb)
                    if frame_embedding is not None:
                        frame_embeddings.append(frame_embedding)
                
                frame_count += 1
                if len(frame_embeddings) >= settings.IDENTITY_CONFIG["max_frames_per_video"]:
                    break
            
            cap.release()
            
            if not frame_embeddings:
                return None
            
            # Apply pooling
            frame_embeddings = np.array(frame_embeddings)
            if settings.IDENTITY_CONFIG["video_pooling"] == "mean":
                return np.mean(frame_embeddings, axis=0)
            elif settings.IDENTITY_CONFIG["video_pooling"] == "max":
                return np.max(frame_embeddings, axis=0)
            else:
                return np.mean(frame_embeddings, axis=0)
                
        except Exception as e:
            logger.error(f"‚ùå Video embedding extraction error: {e}")
            return None
    
    def _extract_single_frame_embedding(self, frame):
        """Extract embedding t·ª´ single frame"""
        try:
            frame_resized = cv2.resize(frame, (160, 160))
            embeddings = self.embedding_model.embeddings([frame_resized])
            return embeddings[0]
        except:
            return None
    
    def _find_best_match(self, query_embedding):
        """T√¨m ng∆∞·ªùi ph√π h·ª£p nh·∫•t trong database"""
        if self.embedding_db is None or query_embedding is None or len(self.embedding_db) == 0:
            return None, 0
        
        try:
            query_embedding = query_embedding.reshape(1, -1)
            db_embeddings = np.array(self.embedding_db)
            
            similarities = cosine_similarity(query_embedding, db_embeddings)[0]
            best_idx = np.argmax(similarities)
            best_similarity = similarities[best_idx]
            
            logger.info(f"üîç Best similarity: {best_similarity:.3f} with threshold: {self.threshold}")
            
            if best_similarity >= self.threshold:
                best_person = self.person_db[best_idx]
                logger.info(f"‚úÖ MATCH FOUND: {best_person['name']} with similarity {best_similarity:.3f}")
                return best_person, best_similarity
            else:
                logger.info(f"‚ùå NO MATCH: Best similarity {best_similarity:.3f} < threshold {self.threshold}")
                return None, best_similarity
                
        except Exception as e:
            logger.error(f"‚ùå Error finding best match: {e}")
            return None, 0
    
    def _get_person_info(self, person_data):
        """L·∫•y th√¥ng tin ng∆∞·ªùi t·ª´ person_data"""
        if person_data['identity_id']:
            return {
                "identity_id": person_data['identity_id'],
                "name": person_data['name'],
                "type": "verified_identity",
                "source": "database"
            }
        else:
            return {
                "identity_id": None,
                "name": person_data['name'],
                "type": "unknown_identity", 
                "source": "training_sample"
            }
    
    async def _run_fake_detection(self, file, file_type):
        """Ch·∫°y model fake detection (Model 2)"""
        try:
            if file_type == "image":
                from .image_service import ImageService
                service = ImageService()
                return await service.process_image(file)
            else:
                from .video_service import VideoService
                service = VideoService()
                return await service.process_video(file)
        except Exception as e:
            logger.error(f"‚ùå Fake detection error: {e}")
            return {
                "status": "error",
                "message": f"Fake detection failed: {str(e)}",
                "data": None,
                "timestamp": datetime.now().isoformat()
            }

    async def process_combined(self, file, file_type):
        """Process file v·ªõi 2 model tu·∫ßn t·ª± theo logic y√™u c·∫ßu"""
        temp_file_path = None
        try:
            # ƒê·∫£m b·∫£o service ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o
            if self.image_fake_detection_model is None or self.video_fake_detection_model is None:
                success = await self.load_identity_system()
                if not success:
                    return {
                        "status": "error",
                        "message": "Models not loaded properly",
                        "data": None,
                        "timestamp": datetime.now().isoformat()
                    }
            
            logger.info("üîÑ Starting combined processing...")
            
            # L∆ØU FILE T·∫†M 1 L·∫¶N DUY NH·∫§T ƒë·ªÉ c·∫£ 2 service d√πng
            file_extension = file.filename.split('.')[-1]
            filename = f"temp_{uuid.uuid4()}.{file_extension}"
            
            if file_type == "image":
                temp_file_path = settings.IMAGE_UPLOAD_DIR / filename
            else:
                temp_file_path = settings.VIDEO_UPLOAD_DIR / filename
            
            # Save file m·ªôt l·∫ßn
            with open(temp_file_path, "wb") as buffer:
                content = await file.read()
                buffer.write(content)
            
            # Reset file pointer ƒë·ªÉ c√≥ th·ªÉ ƒë·ªçc l·∫°i
            await file.seek(0)
            
            # STEP 1: Model 1 - Nh·∫≠n di·ªán danh t√≠nh (so s√°nh embedding)
            query_embedding = await self._extract_embedding_from_path(temp_file_path, file_type)
            if query_embedding is None:
                return {
                    "status": "error", 
                    "message": "Cannot extract face embedding from file",
                    "data": None,
                    "timestamp": datetime.now().isoformat()
                }
            
            best_match, similarity = self._find_best_match(query_embedding)
            identity_found = best_match is not None
            
            # STEP 2: Model 2 - Fake detection (truy·ªÅn ƒë∆∞·ªùng d·∫´n file thay v√¨ file object)
            fake_result = await self._run_fake_detection_from_path(temp_file_path, file_type)
            if fake_result["status"] == "error":
                return fake_result
            
            fake_data = fake_result["data"]
            is_fake = fake_data["label"] == "fake"
            fake_confidence = fake_data["confidence_score"]
            
            # STEP 3: √Åp d·ª•ng logic business theo y√™u c·∫ßu
            if identity_found and not is_fake:
                # ‚úÖ C√≥ trong DB + Real -> Hi·ªán th√¥ng tin ng∆∞·ªùi
                conclusion = "real_verified"
                message = "‚úÖ Ng∆∞·ªùi th·∫≠t - ƒê√£ x√°c minh danh t√≠nh"
                risk_level = "low"
                person_info = self._get_person_info(best_match)
                
            elif identity_found and is_fake:
                # ‚ö†Ô∏è C√≥ trong DB + Fake -> Gi·∫£ m·∫°o
                conclusion = "fake_impersonation"
                message = "‚ö†Ô∏è C·∫£nh b√°o gi·∫£ m·∫°o - ·∫¢nh/video gi·∫£ m·∫°o ng∆∞·ªùi th·∫≠t trong h·ªá th·ªëng"
                risk_level = "high" 
                person_info = self._get_person_info(best_match)
                
            elif not identity_found and not is_fake:
                # ‚ùì Kh√¥ng trong DB + Real -> Ng∆∞·ªùi l·∫° th·∫≠t
                conclusion = "real_unknown" 
                message = "‚ùì Ng∆∞·ªùi l·∫° th·∫≠t - Kh√¥ng c√≥ trong h·ªá th·ªëng"
                risk_level = "medium"
                person_info = None
                
            else:  # not identity_found and is_fake
                # üö® Kh√¥ng trong DB + Fake -> Deepfake nguy hi·ªÉm
                conclusion = "fake_unknown"
                message = "üö® C·∫£nh b√°o gi·∫£ m·∫°o - ·∫¢nh/video gi·∫£ m·∫°o ng∆∞·ªùi l·∫° kh√¥ng c√≥ trong h·ªá th·ªëng"
                risk_level = "critical"
                person_info = None
            
            # Build final result
            result_data = {
                "conclusion": conclusion,
                "message": message, 
                "risk_level": risk_level,
                "identity_verified": identity_found,
                "fake_detected": is_fake,
                "person_info": person_info,
                "similarity_score": float(similarity),
                "fake_confidence": fake_confidence,
                # "processing_details": {
                #     "model_1_identity_match": identity_found,
                #     "model_2_fake_detection": is_fake,
                #     "matched_person": best_match["name"] if identity_found else "Unknown",
                #     "similarity_threshold": self.threshold
                # }
            }
            
            # K·∫øt h·ª£p v·ªõi fake detection data
            combined_data = {**fake_data, **result_data}
            
            return {
                "status": "success",
                "message": message,
                "data": combined_data,
                "timestamp": datetime.now().isoformat()
            }
                
        except Exception as e:
            logger.error(f"‚ùå Combined processing error: {e}")
            return {
                "status": "error",
                "message": f"Combined processing error: {str(e)}",
                "data": None,
                "timestamp": datetime.now().isoformat()
            }
        finally:
            # LU√îN x√≥a file t·∫°m d√π c√≥ l·ªói hay kh√¥ng
            if temp_file_path and os.path.exists(temp_file_path):
                try:
                    os.remove(temp_file_path)
                    logger.info(f"üßπ Cleaned up temp file: {temp_file_path}")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Could not delete temp file: {e}")

    async def _extract_embedding_from_path(self, file_path, file_type):
        """Extract embedding t·ª´ file path (thay v√¨ file object)"""
        try:
            if self.embedding_model is None:
                return None
            
            # Extract embedding t·ª´ file path
            if file_type == "image":
                embedding = self._extract_image_embedding(file_path)
            else:
                embedding = self._extract_video_embedding(file_path)
            
            return embedding
                
        except Exception as e:
            logger.error(f"‚ùå Embedding extraction error: {e}")
            return None

    async def _run_fake_detection_from_path(self, file_path, file_type):
        """Ch·∫°y model fake detection t·ª´ file path"""
        try:
            if file_type == "image":
                from .image_service import ImageService
                service = ImageService()
                # G·ªçi method m·ªõi t·ª´ ImageService ƒë·ªÉ x·ª≠ l√Ω t·ª´ file path
                if hasattr(service, 'process_image_from_path'):
                    return await service.process_image_from_path(file_path)
                else:
                    # Fallback: m·ªü file v√† g·ªçi method c≈©
                    with open(file_path, "rb") as f:
                        from fastapi import UploadFile
                        import io
                        file = UploadFile(filename=file_path.name, file=io.BytesIO(f.read()))
                        return await service.process_image(file)
            else:
                from .video_service import VideoService
                service = VideoService()
                if hasattr(service, 'process_video_from_path'):
                    return await service.process_video_from_path(file_path)
                else:
                    with open(file_path, "rb") as f:
                        from fastapi import UploadFile
                        import io
                        file = UploadFile(filename=file_path.name, file=io.BytesIO(f.read()))
                        return await service.process_video(file)
        except Exception as e:
            logger.error(f"‚ùå Fake detection error: {e}")
            return {
                "status": "error",
                "message": f"Fake detection failed: {str(e)}",
                "data": None,
                "timestamp": datetime.now().isoformat()
            }

    async def update_threshold(self, new_threshold):
        """C·∫≠p nh·∫≠t threshold ƒë·ªông"""
        old_threshold = self.threshold
        self.threshold = new_threshold
        logger.info(f"üîß Threshold updated: {old_threshold} -> {new_threshold}")
        return {"old_threshold": old_threshold, "new_threshold": new_threshold}

    def get_service_status(self):
        """L·∫•y tr·∫°ng th√°i service"""
        return {
            "model_1_identity_loaded": self.identity_model is not None,
            "model_2a_image_fake_detection_loaded": self.image_fake_detection_model is not None,
            "model_2b_video_fake_detection_loaded": self.video_fake_detection_model is not None,
            "embedding_model_loaded": self.embedding_model is not None,
            "database_loaded": self.embedding_db is not None,
            "embedding_count": len(self.embedding_db) if self.embedding_db else 0,
            "current_threshold": self.threshold,
            "model_paths": {
                "identity_model": str(settings.IDENTITY_MODEL_PATH),
                "image_fake_detection": str(settings.IMAGE_MODEL_PATH),
                "video_fake_detection": str(settings.VIDEO_MODEL_PATH)
            }
        }